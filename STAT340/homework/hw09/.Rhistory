test_statistics[i] <- permute_and_compute( before, after );
}
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
NMC <- 1e5;
test_statistics <- rep( 0, NMC );
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
observed_tstat <- mean(after)-mean(before)
mean(test_statistics <= observed_tstat)
NMC <- 1e5;
test_statistics <- rep( 0, NMC );
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
observed_tstat <- mean(after)-mean(before)
mean(test_statistics <= observed_tstat | test_statistics >= observed_tstat)
NMC <- 1e5;
test_statistics <- rep( 0, NMC );
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
observed_tstat <- mean(after)-mean(before)
mean(test_statistics <= observed_tstat | test_statistics >= -observed_tstat)
NMC <- 1e5;
test_statistics <- rep( 0, NMC );
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
abline( v=-(mean(after)-mean(before)), lw=3, col='red' )
observed_tstat <- mean(after)-mean(before)
mean(test_statistics <= observed_tstat | test_statistics >= -observed_tstat)
NMC <- 1e5;
test_statistics <- rep( 0, NMC );
for(i in 1:NMC ) {
test_statistics[i] <- permute_and_compute( before, after );
}
hist( test_statistics )
abline( v=mean(after)-mean(before), lw=3, col='red' )
abline( v=-(mean(after)-mean(before)), lw=3, col='red' )
observed_tstat <- mean(after)-mean(before)
p_value <- mean(test_statistics <= observed_tstat | test_statistics >= -observed_tstat)
p_value
MNC <- 1e5
meme_comments <- function() {
p <- 0.1
# Getting a 1 means it is a meme comment
meme <- rbinom(416, 1, p)
return(sum(meme))
}
simulations <- replicate(MNC, meme_comments())
hist(simulations,
main = "Distribution of Number of meme comments per 416 comments",
xlab = "Number of meme comments",
ylab = "Frequency")
observed_number_meme_comments <- 47
# find p-value of the observed number of awarded buildings
abline(v = observed_number_meme_comments-0.5, col = "red")
greater_than_obs <- mean(simulations >= observed_number_meme_comments)
greater_than_obs
?rcauchy
generate_Cauchydata <- function(n, location = 0) {
# Generate n iid draws from a  Cauchy distribution with scale 1 and given location
#hint: rcauchy
return(rcauchy(n,location))
# TODO: code goes here.
}
generate_Cauchydata <- function(n, location = 0) {
# Generate n iid draws from a  Cauchy distribution with scale 1 and given location
#hint: rcauchy
return(rcauchy(n,location))
}
NMC <- 10000
results <- numeric(NMC)
for (i in 1:NMC) {
sampleA <- generate_Cauchydata(20, 10)
sampleB <- generate_Cauchydata(20, 10)
test_results <- t.test(sampleA, sampleB, var.equal = TRUE)
pval <- test_results$p.value
results[i] <- pval
}
results
NMC <- 10000
results <- numeric(NMC)
for (i in 1:NMC) {
sampleA <- generate_Cauchydata(20, 10)
sampleB <- generate_Cauchydata(20, 10)
test_results <- t.test(sampleA, sampleB, var.equal = TRUE)
pval <- test_results$p.value
results[i] <- pval
}
results
mean(results)
NMC <- 10000
alpha <- 0.05
type1_errors <- 0 #
for (i in 1:NMC) {
sampleA <- generate_Cauchydata(20, 10)
sampleB <- generate_Cauchydata(20, 10)
test_results <- t.test(sampleA, sampleB, var.equal = TRUE)
pval <- test_results$p.value
if (pval <= alpha) {
type1_errors <- type1_errors + 1
}
}
# Calculate the estimated Type I error rate
type1_error_rate <- type1_errors / NMC
type1_error_rate
permutation_test <- function(sampleA, sampleB, M_permute) {
observed_diff <- mean(sampleA) - mean(sampleB)
combined <- c(sampleA, sampleB)
more_extreme <- 0
for (i in 1:M_permute) {
shuffled <- sample(combined)
newA <- shuffled[1:length(sampleA)]
newB <- shuffled[(length(sampleA) + 1):length(combined)]
new_diff <- mean(newA) - mean(newB)
if (abs(new_diff) >= abs(observed_diff)) {
more_extreme <- more_extreme + 1
}
}
p_value <- more_extreme / M_permute
return(p_value)
}
NMC <- 10000
M_permute <- 100
alpha <- 0.05
rejections <- 0
for (i in 1:NMC) {
sampleA <- generate_Cauchydata(20, 10)
sampleB <- generate_Cauchydata(20, 10)
p_value <- permutation_test(sampleA, sampleB, M_permute)
if (p_value <= alpha) {
rejections <- rejections + 1
}
}
# Calculate the rejection rate
rejection_rate <- rejections / NMC
rejection_rate
1 - pnorm ( (0-2) / sqrt(1.6))
1 - pnorm ( (0-2) / sqrt(3.2))
1 - pnorm ( (0-2) / 4
)
run_sample_mean_trial <- function( n ) {
# Parameters for the Gamma distribution
k <- 2
theta <- 3
# Generate n samples from the Gamma distribution
samples <- rgamma(n, shape = k, scale = theta)
# Return the mean of the samples
mean(samples)
}
estimate_sample_mean_variance <- function( n, M ) {
# Initialize a vector to store the means from each trial
sample_means <- numeric(M)
# Run M trials, each with n samples
for (i in 1:M) {
sample_means[i] <- run_sample_mean_trial(n)
}
# Calculate and return the variance of the sample means
var(sample_means)
}
library(ggplot2)
# Sample sizes to test
n_values <- c(10, 20, 50, 100, 200, 500, 1000)
# Number of trials for estimating variance
M <- 1000
# Estimate variance for each sample size
var_estimates <- sapply(n_values, function(n) {
estimate_sample_mean_variance(n, M)
})
# Plotting the estimated variances against sample sizes
data <- data.frame(SampleSize = n_values, EstimatedVariance = var_estimates)
ggplot(data, aes(x = SampleSize, y = EstimatedVariance)) +
geom_point() +
geom_line() +
scale_x_log10() + scale_y_log10() +
labs(title = "Estimated Variance vs. Sample Size",
x = "Sample Size (n)",
y = "Estimated Variance of Sample Mean") +
theme_minimal()
# Overlaying f(t) = c/t
# We choose c based on the theoretical relationship between variance and sample size
# For a Gamma distribution with k = 2, theta = 3, variance = (k*theta^2), so we use this to guide our choice of c
c_value <- 2 * 3^2  # Theoretical variance of the distribution
# Adding the theoretical line to the plot
data$TheoreticalVariance <- c_value / data$SampleSize
ggplot(data, aes(x = SampleSize)) +
geom_line(aes(y = EstimatedVariance), color = "blue") +
geom_line(aes(y = TheoreticalVariance), color = "red", linetype = "dashed") +
scale_x_log10() + scale_y_log10() +
labs(title = "Estimated vs. Theoretical Variance",
x = "Sample Size (n)",
y = "Variance") +
theme_minimal() +
geom_point(aes(y = EstimatedVariance), color = "blue") +
annotate("text", x = 50, y = c_value / 50, label = "Theoretical Variance (c/n)", color = "red")
# define running average function
# can be specified as cumulative sum / index of element
running_mean <- function(vec) {
cumsum(vec) / seq_along(vec)
}
# Generate a bunch of lambda=5.0 Poissons and compute running mean.
poisdraws <- rpois(n=1000, lambda=5.0);
runmean <- running_mean( poisdraws );
# Plot the running mean
plot( runmean );
abline(h=5.0, col='red'); # Mean is 5.0
# Function to estimate the probability
estimate_probability <- function(n, lambda, epsilon, M) {
within_epsilon_count <- 0
for (i in 1:M) {
# Generate n samples from Poisson distribution
samples <- rpois(n, lambda)
# Compute the sample mean
sample_mean <- mean(samples)
# Check if the sample mean is within epsilon of lambda
if (abs(sample_mean - lambda) <= epsilon) {
within_epsilon_count <- within_epsilon_count + 1
}
}
# Calculate the probability
probability <- within_epsilon_count / M
return(probability)
}
# Parameters
n <- 250
lambda <- 5.0
epsilon <- 0.25
M <- 10000  # Number of Monte Carlo iterates
# Estimate the probability
probability_estimate <- estimate_probability(n, lambda, epsilon, M)
probability_estimate
running_var <- function(vec) {
n <- length(vec)
running_mean <- cumsum(vec) / seq_along(vec)
running_mean_sq <- cumsum(vec^2) / seq_along(vec)
running_var <- running_mean_sq - running_mean^2
return(running_var)
}
running_var <- function(vec) {
n <- length(vec)
running_mean <- cumsum(vec) / seq_along(vec)
running_mean_sq <- cumsum(vec^2) / seq_along(vec)
running_var <- running_mean_sq - running_mean^2
return(running_var)
}
pois_draws <- rpois(n=1000, lambda=5.0)
run_var <- running_var(pois_draws)
# Plot the running variance
plot(run_var, type = "l", main = "Running Variance of Poisson Draws", xlab = "Sample Size", ylab = "Running Variance")
abline(h = lambda, col = "red")
# Generate samples
samples <- rnorm(1000, mean = 0, sd = 1)
# Compute running variance
run_var <- running_var(samples)
# Plot the running variance
plot(run_var, type = 'l', xlab = "Sample Size", ylab = "Running Variance",
main = "Running Variance of a Standard Normal Distribution")
abline(h = 1, col = 'red')
# Generate samples
samples <- rnorm(10000, mean = 0, sd = 1)
# Compute running variance
run_var <- running_var(samples)
# Plot the running variance
plot(run_var, type = 'l', xlab = "Sample Size", ylab = "Running Variance",
main = "Running Variance of a Standard Normal Distribution")
abline(h = 1, col = 'red')
knitr::opts_chunk$set(echo = TRUE)
download.file('https://kdlevin-uwstat.github.io/STAT340-Fall2021/hw/03/mule_kicks.csv', destfile='mule_kicks.csv')
mule_kicks = read.csv('mule_kicks.csv', header=TRUE)
head(mule_kicks)
View(mule_kicks)
#TODO: estimate the rate parameter.
lambdahat <- mean(mule_kicks$deaths) # TODO: write code store your estimate in lambdahat.
lambdahat
?rpois
mc_resampling <- function (reps, sample_size, lambda) {
estimators <- numeric(reps)
for (i in 1:reps){
sample <- rpois(sample_size,lambda)
estimators[i] <- mean(sample)
}
return (estimators)
}
hist(mc_resampling(1e4, length(mule_kicks), lambdahat))
#TODO: code goes here.
mc_resampling <- function (reps, sample_size, lambda) {
estimators <- numeric(reps)
for (i in 1:reps){
sample <- rpois(sample_size,lambda)
estimators[i] <- mean(sample)
}
return (estimators)
}
hist(mc_resampling(1e4, length(mule_kicks$deaths), lambdahat))
#TODO: code goes here.
mc_resampling <- function (reps, sample_size, lambda) {
estimators <- numeric(reps)
for (i in 1:reps){
sample <- rpois(sample_size,lambda)
estimators[i] <- mean(sample)
}
return (estimators)
}
# Simulate the sampling distribution of the estimator
simulated_means <- mc_resampling(1e4, length(mule_kicks$deaths), lambdahat)
# Construct a 95% confidence interval from the simulated sample means
alpha <- 0.05
lower_bound <- quantile(simulated_means, alpha / 2)
upper_bound <- quantile(simulated_means, 1 - (alpha / 2))
# Display the histogram of simulated_means with the CI bounds
hist(simulated_means, main="Distribution of Simulated Sample Means with CI", xlab="Lambda Hat")
abline(v = c(lower_bound, upper_bound), col = "red", lwd = 2)
# Print the CI
cat("95% Confidence Interval for Lambda:", lower_bound, upper_bound, "\n")
#TODO: code goes here.
library(ggplot2)
# Generate a histogram of observed data
ggplot(mule_kicks, aes(x=deaths)) +
geom_histogram(binwidth=1, color="black", fill="lightblue", boundary=0) +
labs(title="Histogram of Mule Kick Deaths", x="Number of Deaths", y="Frequency") +
theme_minimal()
# Overlay the expected Poisson distribution
lambda_est <- mean(mule_kicks$deaths)
deaths_seq <- 0:max(mule_kicks$deaths)
expected_freq <- dpois(deaths_seq, lambda=lambda_est) * nrow(mule_kicks)
lines(deaths_seq, expected_freq, col="red", type="o")
library(ggplot2)
# Generate a histogram of observed data
ggplot(mule_kicks, aes(x=deaths)) +
geom_histogram(binwidth=1, color="black", fill="lightblue", boundary=0) +
labs(title="Histogram of Mule Kick Deaths", x="Number of Deaths", y="Frequency") +
theme_minimal()
# Overlay the expected Poisson distribution
lambda_est <- mean(mule_kicks$deaths)
deaths_seq <- 0:max(mule_kicks$deaths)
expected_freq <- dpois(deaths_seq, lambda=lambda_est) * nrow(mule_kicks)
lines(deaths_seq, expected_freq, col="red", type="o")
library(ggplot2)
obs_freq <- table(mule_kicks$deaths)
lambdahat <- mean(mule_kicks$deaths)
deaths_seq <- 0:max(as.integer(names(obs_freq))) # Ensure coverage of all observed deaths
expected_freq <- dpois(deaths_seq, lambdahat) * length(mule_kicks$deaths)
# Plot observed frequencies
barplot(obs_freq, names.arg = names(obs_freq), main = "Observed vs. Expected Frequencies", xlab = "Deaths", ylab = "Frequency")
# Overlay expected frequencies
lines(deaths_seq, expected_freq, col = "red", type = "o")
?rbinom
# Assume p=0.82 is truth
phat <- 0.82
desired_prob <- 0.99
min_functional <- 5
simulate_batch <- function(batch_size, p) {
rbinom(1, batch_size, p) >= min_functional
}
# Function to estimate probability for a given batch size
estimate_prob <- function(batch_size, p, simulations = 1e4) {
mean(replicate(simulations, simulate_batch(batch_size, p)))
}
batch_size <- 1
while (estimate_prob(batch_size, p) < desired_prob) {
batch_size <- batch_size + 1
}
# Assume p=0.82 is truth
phat <- 0.82
desired_prob <- 0.99
min_functional <- 5
simulate_batch <- function(batch_size, p) {
rbinom(1, batch_size, p) >= min_functional
}
# Function to estimate probability for a given batch size
estimate_prob <- function(batch_size, p, simulations = 1e4) {
mean(replicate(simulations, simulate_batch(batch_size, p)))
}
batch_size <- 1
while (estimate_prob(batch_size, phat) < desired_prob) {
batch_size <- batch_size + 1
}
batch_size
data(cars)
head(cars)
data(cars)
head(cars)
plot(cars$speed, cars$dist, main = "Stopping Distance vs Speed",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
linear_model <- lm(dist ~ speed, data = cars)
summary(linear_model)
plot(cars$speed, cars$dist, main = "Stopping Distance vs Speed with Linear Regression Line",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
abline(linear_model, col = "blue")
linear_model <- lm(dist ~ speed, data = cars)
summary(linear_model)
plot(cars$speed, cars$dist, main = "Stopping Distance vs Speed with Linear Regression Line",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
abline(linear_model, col = "red")
linear_model <- lm(dist ~ speed, data = cars)
summary(linear_model)
plot(cars$speed, cars$dist, main = "Stopping Distance vs Speed with Linear Regression Line",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
abline(linear_model, col = "blue")
plot(linear_model)
data(cars)
head(cars)
plot(cars$speed, cars$dist, main = "Stopping Distance vs Speed",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
linear_model <- lm(dist ~ speed, data = cars)
summary(linear_model)
summary(linear_model)
nonlinear_model <- lm(dist ~ I(speed^2), data = cars)
summary(nonlinear_model)
library(ggplot2)
# Creating a data frame for predictions
pred_data <- data.frame(speed = speed_seq,
Linear = dist_pred_linear,
Nonlinear = dist_pred_nonlinear)
library(ggplot2)
# Creating a data frame for predictions
pred_data <- data.frame(speed = speed,
Linear = dist_pred_linear,
Nonlinear = dist_pred_nonlinear)
speed_seq <- seq(min(cars$speed), max(cars$speed), length.out = 100)
dist_pred_linear <- predict(linear_model, newdata = data.frame(speed = speed_seq))
dist_pred_nonlinear <- predict(nonlinear_model, newdata = data.frame(speed = speed_seq))
plot(cars$speed, cars$dist,
main = "Stopping Distance vs. Speed",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
lines(speed_seq, dist_pred_linear, col = "blue")  # Linear model in blue
lines(speed_seq, dist_pred_nonlinear, col = "red")  # Nonlinear model in red
speed_seq <- seq(min(cars$speed), max(cars$speed), length.out = 100)
dist_pred_linear <- predict(linear_model, newdata = data.frame(speed = speed_seq))
dist_pred_nonlinear <- predict(nonlinear_model, newdata = data.frame(speed = speed_seq))
plot(cars$speed, cars$dist,
main = "Stopping Distance vs. Speed",
xlab = "Speed (mph)", ylab = "Stopping Distance (ft)", pch = 19)
lines(speed_seq, dist_pred_linear, col = "blue")  # Linear model
lines(speed_seq, dist_pred_nonlinear, col = "red")  # Nonlinear model
plot(linear_model, which=1, main="Linear Model Residuals")
plot(nonlinear_model, which=1, main="Quadratic Model Residuals")
model_wt <- lm(mpg ~ wt, data = mtcars)
summary(model_wt)
model_hp <- lm(mpg ~ hp, data = mtcars)
summary(model_hp)
model_disp <- lm(mpg ~ disp, data = mtcars)
summary(model_disp)
model_wt <- lm(mpg ~ wt, data = mtcars)
summary(model_wt)
model_hp <- lm(mpg ~ hp, data = mtcars)
summary(model_hp)
model_disp <- lm(mpg ~ disp, data = mtcars)
summary(model_disp)
model_wt_hp <- lm(mpg ~ wt + hp, data = mtcars)
summary(model_wt_hp)
model_wt_disp <- lm(mpg ~ wt + disp, data = mtcars)
summary(model_wt_disp)
model_hp_disp <- lm(mpg ~ hp + disp, data = mtcars)
summary(model_hp_disp)
plot(model_all)
model_all <- lm(mpg ~ wt + hp + disp, data = mtcars)
summary(model_all)
plot(model_all)
?mtcars
lm.mtcars = lm(mpg ~ cyl + gear + carb, data=mtcars)
plot(lm.mtcars,ask=F,which=1:2)
summary(lm.mtcars)
confint(lm.mtcars, level = 0.95)
library(MASS)
head(cats)
plot(cats)
plot(cats$Bwt, cats$Hwt,
main = "Scatter Plot of Heart Weight vs. Body Weight",
xlab = "Body Weight (kg)",
ylab = "Heart Weight (g)",
pch = 19, col = "blue")
lm.cats = lm(Hwt ~ Bwt, data = cats)
summary(lm.cats)
coef(lm.cats)
plot(cats$Bwt, cats$Hwt,
main = "Scatter Plot of Heart Weight vs. Body Weight",
xlab = "Body Weight (kg)",
ylab = "Heart Weight (g)",
pch = 19, col = "blue")
library(ggplot2)
ggplot(cats, aes(x = Bwt, y = Hwt, color = Sex)) +
geom_point() +
labs(title = "Heart Weight vs. Body Weight by Sex",
x = "Body Weight (kg)",
y = "Heart Weight (g)",
color = "Sex") +
theme_minimal()
lm.cats.interaction = lm(Hwt ~ Bwt * Sex, data = cats)
summary(lm.cats.interaction)
multData <- read.csv("multData.csv")
setwd("~/Desktop/STAT 340/homework/hw09")
multData <- read.csv("multData.csv")
lm_model <- lm(Y ~ X1 + X2, data = multData)
summary(lm_model)
lm_model_interaction = lm(Y ~ X1 + X2 + X1:X2, data = multData)
summary(lm_model_interaction)
lm_model_full = lm(Y ~ X1 + X2 + X1:X2 + X3, data = multData)
summary(lm_model_full)
lm_model_higher_order = lm(Y ~ X1 + X2 + X1:X2 + X3 + I(X3^2) + I(X3^3), data = multData)
summary(lm_model_higher_order)
