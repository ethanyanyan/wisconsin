---
title: "STAT 340 Discussion 01: R review"
output: html_document
author: "Will Brooker, Josh Fisher, Sujay Tata, Ethan Yan"
---

## XKCD comic

We like to start discussion sections with a relevant XKCD comic (see
[XKCD.com](xkcd.com) for lots more).

<center><a href="https://xkcd.com/833/"><img id="comic" src="https://imgs.xkcd.com/comics/convincing.png" title="" style="width:555px;"></a></center>

Today's exercises are intended as a review of basic R features and operations.

## 1) Vector operations

Remember that in R, if an operation works on a single number, it will usually
also work entry-wise on a vector. For example, if you multiply a number by a
vector, each entry in the vector will be multiplied by that number. If you
multiply two vectors of the same length, the first number of both vectors will
be multiplied, and the second number of both vectors will be multiplied, etc. A
similar pattern will also work for functions like `exp()` or `pnorm()`. Applying
a function like these to a vector will apply the function to every entry of the
vector. Functions that do this are called *vectorized*.

   a. Create a vector of the numbers 1 to 25 (try to do this without writing out each individual number). Multiply the vector by 2 to get a vector of all the even numbers less than or equal to 50.
   b. Next, square this vector. Check that the entries of the result are the squares of the first 25 positive even numbers.
   c. Find the mean of this vector and subtract it from each element of the vector.
   d. Using `>=`, compare this vector with 0 to show if each number is greater than or equal to 0. Use `sum()` on this resultant vector to count how many numbers satisfy this criterion. Alternatively, use `mean()` to get the proportion (think about why this works!).
   e. Divide the interval $(0,1)$ into 15 evenly spaced numbers (**not including** 0 and 1). (Hint: see `?ppoints`). Then, use `qnorm()` to get a vector of 15 points evenly spaced out along the quantiles of the normal distribution. __Note:__ this is how you obtain the theoreticals for a [QQ-plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot), which you may have seen in your intro classes.
   
> a

```{r}
vector25 <- c(1:25)
mult2 <- vector25 * 2

mult2
```

> b

```{r}
square <- vector25 ** 2

square
```

> c

```{r}
mean <- mean(square)

subtracted <- square - mean

subtracted
```

> d

```{r}
greater_than_zero <- subtracted >= 0

sum(greater_than_zero)
```

> e

```{r}
points <- ppoints(15)
points

normal_quantiles <- qnorm(points)
normal_quantiles
```

## 2) Functions

Functions are a useful way of creating a tool that can be used over and over
again. Write a function for each of the following parts:

1. Given an `n` and `k`, computes the binomial coefficient,

$$\binom{n}{k} = \frac{ n! }{ (n-k)! k! }.$$
You may assume that `n` and `k` are both integers and that $0 \le k \le n$.
You may find the `factorial` function in R helpful. See `?factorial` for more information. Be careful that your function correctly handles cases like when $n=0$.

```{r}
binomial_coefficient <- function(n, k) {
  if (n == 0 && k == 0) {
    return(1)
  } else if (k > n) {
    return(0)
  }

  return(factorial(n) / (factorial(n - k) * factorial(k)))
}
```

**Note:** functions in R have different scope than the global environment. Read
[this](https://www.geeksforgeeks.org/scope-of-variable-in-r/) for a helpful
guide about this. Also note that declaring/updating a global variable from
inside a function is considered bad practice, since it can easily introduce bugs
that are very difficult to detect and fix. Avoid this if you can.

2. Simulates rolling `n` 6-sided dice and gives the average of the outcomes. `n` should have a default value of 2.

```{r}
roll_dice <- function(n = 2) {
  rolls <- sample(1:6, n, replace = TRUE)
  
  average <- mean(rolls)
  
  return(average)
}

```
3. Manually (i.e. without using `sd()`) compute the sample standard deviation of a vector. Make sure you don't call this function `sd`-- pick something else!

```{r}
std_dev <- function(x) {
  n <- length(x)
  
  if (n <= 1) {
    return(NA)
  }

  mean_x <- mean(x)
  
  sum_squared_devs <- sum((x - mean_x)^2)
  
  std_dev <- sqrt(sum_squared_devs / (n - 1))
  
  return(std_dev)
}

```

## 3) Conditional executions

It's important to be able to write clear and effective conditionals (if, else,
etc...) in R. It's often very useful to check if a condition is satisfied and
then do different things depending on the outcome.

Briefly review sections 7.3-7.5 of [this
page](https://discdown.org/rprogramming/conditional-execution.html#conditional-execution-if-else-statement)
here. Then, write a function `is_even` (remember that thing about good function
names?) that takes a single argument `n` (you may assume `n` is an integer), and
returns `TRUE` if `n` is even and `FALSE` otherwise. **Hint:** `x %% y`, read "x
modulo y", returns the remainder when dividing `x` by `y`. This is an easy way
to check if a number is odd or even: a number $n$ is even if and only if n
modulo 2 is zero.

```{r}
is_even <- function(n) {
  return (n%%2 == 0)
}
```

## 4) For-loops

For-loops are a useful way of repeating a step a set number of times.
See [here](https://discdown.org/rprogramming/loops.html#for-loops) for a review.

Write a function that repeats the following experiment `n` times (`n` should be the only argument to your function, and you may assume that `n` is a positive integer), with a default `n=1000`:

   - draw 5 cards from a standard deck of playing cards (hint: for this problem, you can represent a deck as the vector 1,2,...,13 repeated 4 times)
   - drop the lowest and highest card (if there are ties, just drop one of
   the cards that are tied).
   - take the mean of the remaining three numbers and stores them in a vector
   - return the vector of means observed in the `n` repetitions of this experiment.
   That is, you should be returning a vector of length `n`.
   
```{r}

repeat_experiment <- function(n = 1000) {
  means <- numeric(n) 
  
  for (i in 1:n) {
    deck <- rep(1:13, 4)
    
    drawn_cards <- sample(deck, 5)
    drawn_cards <- sort(drawn_cards)
    
    remaining_cards <- drawn_cards[2:length(drawn_cards)-1]
    
    if (length(remaining_cards) > 3) {
      remaining_cards <- head(remaining_cards, 3)
    }
    
    means[i] <- mean(remaining_cards)
  }
  
  return(means)
}

```

## 5) Random variables and LLN

#### 5a)

For each of the following, identify one or more random variables that can be used to model the outcome.

   - The number of cars that pass your house in an hour.
   - The number of times you need to try before you make a 3-point shot.
   - The number of people in a clinical trial who recover after going through an experimental treatment.
   - The number you get when rolling a 20-sided die.

***

- The number of cars that pass your house in an hour.
  - Poisson
- The number of times you need to try before you make a 3-point shot.
  - Geometric
- The number of people in a clinical trial who recover after going through an experimental treatment.
  - Binomial
- The number you get when rolling a 20-sided die.
  - Discrete Uniform

***
   
#### 5b)

Choose a type of random variable from lecture (e.g., normal, binomial, poisson, geometric, exponential, uniform, etc...) and choose some parameters. Write down what the theoretical mean of this particular distribution is (you can use Wikipedia to get the expected value for your random variable if you don't know it off-hand).

***

- Binomial Random Variable
  - 50 clinical trials, 0.35 probability of people who recover from clinical trial
  - Theoretical Mean is np = 50 * 0.35

```{r}
50 * 0.35
```


***

#### 5c)

Randomly generate at least 1000 observations of the variable you chose (if your
computer can generate more, go ahead!). Then, use the `running_mean()` function
defined below to compute a running mean (i.e., the $k$-th entry of the output is
the mean of the first $k$ numbers in the input).

```{r}
# define running average function
# can be specified as cumulative sum / index of element
running_mean <- function(vec) {
   cumsum(vec) / seq_along(vec)
}
```
   
```{r}
library(ggplot2)

n <- 50 
p <- 0.35 
size <- 10000
binom_rvs <- rbinom(size, n, p)

running_means <- running_mean(binom_rvs)
```
   
Plot this running mean using the `plot()` function, and use `abline()` to add a
horizontal red line at your previously-computed theoretical mean. If you like,
you can use `ggplot2` for this, instead.

```{r}
plot(running_means, type = "l", col = "blue", xlab = "Number of Observations", ylab = "Running Mean")
abline(h = 50 * 0.35, col = "red")
```

The law of large numbers (LLN) states that the sample mean of a large number of
random variables will be close to the population mean (i.e., the expectation),
and the sample mean will be closer to the population mean (on average) the
larger the sample size is.

Is your plot consistent with the Law of Large Numbers? Why or why not?

***

The Law of Large Numbers states that as the number of trials increases, the sample mean will converge to the expected value. In my plot, it is observed that the running mean gets closer to the theoretical mean (red line) as the number of observations increases. This is consistent with the LLN, demonstrating that the sample mean approaches the population mean as the sample size grows.

***
